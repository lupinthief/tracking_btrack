{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe44a4c",
   "metadata": {},
   "source": [
    "# Import segmented iceberg maps to btrack and attempt tracking\n",
    "Perform Bayesian tracking of icebergs using 'btrack'. Much of the code here is copied from the btrack documentation\n",
    "https://github.com/quantumjot/BayesianTracker\n",
    "\n",
    "btrack v>=0.5 must be installed from branch 'visual-features'using Python 3.8. Conflicts arise with fiona when using Python 3.8+ so this notebook does not handle geolocated images or clipping to shapefile ROIs. Assumes all specified images have common footprint. \n",
    "\n",
    "Iceberg segmentations stored in 'data' folder are sample outputs of a fully unsupervised classifier for Sentinel-1 SAR imagery over a one-year period in 2019-2020.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970bb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y [btrack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ffaa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/quantumjot/BayesianTracker.git@visual-features\n",
      "  Cloning https://github.com/quantumjot/BayesianTracker.git (to revision visual-features) to c:\\users\\benevans\\appdata\\local\\temp\\pip-req-build-e4fr127t\n",
      "  Resolved https://github.com/quantumjot/BayesianTracker.git to commit a6e739d6d4dd32730c22039f98e7748818e2b62c\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/quantumjot/BayesianTracker.git 'C:\\Users\\benevans\\AppData\\Local\\Temp\\pip-req-build-e4fr127t'\n",
      "  Running command git checkout -b visual-features --track origin/visual-features\n",
      "  branch 'visual-features' set up to track 'origin/visual-features'.\n",
      "  Switched to a new branch 'visual-features'\n",
      "ERROR: Package 'btrack' requires a different Python: 3.7.13 not in '>=3.8'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: scikit-image>=0.16.2 in c:\\users\\benevans\\anaconda3\\envs\\py37_btrack\\lib\\site-packages (from btrack==0.5.0) (0.19.2)\n",
      "Requirement already satisfied: pooch>=1.0.0 in c:\\users\\benevans\\anaconda3\\envs\\py37_btrack\\lib\\site-packages (from btrack==0.5.0) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\benevans\\anaconda3\\envs\\py37_btrack\\lib\\site-packages (from btrack==0.5.0) (1.21.5)\n",
      "Requirement already satisfied: cvxopt>=1.2.0 in c:\\users\\benevans\\anaconda3\\envs\\py37_btrack\\lib\\site-packages (from btrack==0.5.0) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\benevans\\anaconda3\\envs\\py37_btrack\\lib\\site-packages (from btrack==0.5.0) (1.7.3)\n",
      "Requirement already satisfied: h5py>=2.10.0 in c:\\users\\benevans\\anaconda3\\envs\\py37_btrack\\lib\\site-packages (from btrack==0.5.0) (3.6.0)\n",
      "Requirement already satisfied: pydantic>=1.9.0 in c:\\users\\benevans\\anaconda3\\envs\\py37_btrack\\lib\\site-packages (from btrack==0.5.0) (1.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/quantumjot/BayesianTracker.git@visual-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2075f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "#import fiona\n",
    "#import rasterio\n",
    "import btrack\n",
    "import napari\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.measure import regionprops, regionprops_table, label\n",
    "from skimage.morphology import remove_small_objects\n",
    "#import DP_Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c44e5",
   "metadata": {},
   "source": [
    "Function to ensure all imported subsets are the same size as the first one processed even if underlying image extent and precise pixel geolocation differs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15f9d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_clip(arr, rows,cols):\n",
    "    \n",
    "    if arr.shape[0]>rows:\n",
    "        arr=arr[0:rows, :]\n",
    "    elif arr.shape[0]<rows:\n",
    "        pad_rows=rows-arr.shape[0]\n",
    "        # npad is a tuple of (n_before, n_after) for each dimension\n",
    "        npad = ((0, pad_rows), (0, 0))\n",
    "        arr = np.pad(arr, pad_width=npad, mode='constant', constant_values=0)\n",
    "        \n",
    "    if arr.shape[1]>cols:\n",
    "        arr=arr[:, 0:cols]\n",
    "    elif arr.shape[1]<cols:\n",
    "        pad_cols=cols-arr.shape[1]\n",
    "        npad = ((0,0), (0, pad_cols))\n",
    "        arr = np.pad(arr, pad_width=npad, mode='constant', constant_values=0)\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb5d08",
   "metadata": {},
   "source": [
    "Function to construct a numpy array stack from segmentations in specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39d62be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_arr(files, minsize=1):\n",
    "    \"\"\"Segmentation as numpy array.\"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    #files=files.sort()\n",
    "    for filename in files:\n",
    "        img=imread(filename)\n",
    "        \n",
    "        if filename == files[0]: #if first image get the shape to apply to subsequent images\n",
    "            rows=img.shape[0]\n",
    "            cols=img.shape[1]\n",
    "        \n",
    "        img=pad_or_clip(img, rows, cols)\n",
    "        labs=label(img, background=0)\n",
    "        cleaned= remove_small_objects(labs, min_size=minsize)\n",
    "        labs=label(cleaned, background=0)#re-label for continuous numbering\n",
    "        stack.append(labs)\n",
    "    return np.stack(stack, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd712c7",
   "metadata": {},
   "source": [
    "Function to rescale values of all visual features attached to btrack objects to interval 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28f159fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise/rescale all attached features to range 0-1\n",
    "def normalise_visual_features(objects):\n",
    "    import copy\n",
    "    objects2=copy.copy(objects)#TODO doesn't seem to stop original objects changing\n",
    "    #initialise variables to store min and max of each\n",
    "    min_vals={}\n",
    "    max_vals={}\n",
    "    #Loop objects to find min and max for each property\n",
    "    for obj in objects2:\n",
    "        for prop in obj.properties:\n",
    "            #collate minimum values\n",
    "            if prop in min_vals:\n",
    "                if min_vals[prop]>obj.properties[prop]:#if smaller than current min\n",
    "                    min_vals[prop]=obj.properties[prop]\n",
    "            else:\n",
    "                min_vals[prop]=obj.properties[prop]#add dictionary entry with value\n",
    "        \n",
    "            #repeat for maximum values\n",
    "            if prop in max_vals:\n",
    "                if max_vals[prop]<obj.properties[prop]:\n",
    "                    max_vals[prop]=obj.properties[prop] # if bigger than current max\n",
    "            else:\n",
    "                max_vals[prop]=obj.properties[prop]\n",
    "    \n",
    "    #Repeat the loop over objects and min-max scale the property values\n",
    "    for obj in objects2:\n",
    "        for prop in obj.properties:\n",
    "            newprop=(obj.properties[prop]-min_vals[prop])/(max_vals[prop]-min_vals[prop])\n",
    "            obj.properties[prop]=newprop\n",
    "            \n",
    "    return objects2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29e19d",
   "metadata": {},
   "source": [
    "Set up paths to example data and ROI shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b56e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=os.path.join(Path().resolve(), \"data\")\n",
    "#PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57f7c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example segmentations\n",
    "files = glob.glob(os.path.join(PATH, 'Iceberg_Detections\\Icebergs*subset.tif'))\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939b98c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20191003T042808_5F90subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20191022T041956_1C46subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20191103T041956_EAC2subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20191115T041956_8217subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20191127T041955_786Dsubset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20191209T041955_1F16subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200102T041954_4277subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200114T041954_A389subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200119T042805_491Dsubset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200126T041953_8EF9subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200207T041953_4DDEsubset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200219T041953_4BE2subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200302T041952_1182subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200314T041953_28DCsubset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200419T041954_489Csubset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200611T042808_B1A8subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200817T042000_BFE7subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200829T042001_18C4subset.tif',\n",
       " 'C:\\\\Users\\\\benevans\\\\OneDrive - NERC\\\\Documents\\\\Icebergs\\\\Tracking\\\\tracking_btrack\\\\data\\\\Iceberg_Detections\\\\Icebergs_20200915T042813_BD27subset.tif']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a04562",
   "metadata": {},
   "source": [
    "Build stack of segmented images including only objects greater than specified size (lower limit for detection algorithm is 63 pixels or 0.1km^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7831748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 5315, 3370)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack = segmentation_arr(files, minsize=63)\n",
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a5494",
   "metadata": {},
   "source": [
    "Define visual features to calculate in call to regionprops and then those that we want to use in tracking updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4863d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to be computed by regionprops\n",
    "FEATURES_Regionprops = [\n",
    "  \"area\",\n",
    "  \"major_axis_length\",\n",
    "  \"minor_axis_length\",\n",
    "  \"moments_hu\"\n",
    "]\n",
    "\n",
    "# features to be used for tracking updates - note that each Hu moment we want to use needs to be specified individually - \n",
    "# hence can't just pass Features_Regionprops\n",
    "FEATURES = [\n",
    "  \"area\",\n",
    "  \"major_axis_length\",\n",
    "  \"minor_axis_length\",\n",
    "  \"moments_hu-0\",\n",
    "  \"moments_hu-1\",\n",
    "  \"moments_hu-2\",\n",
    "  \"moments_hu-3\",\n",
    "  \"moments_hu-4\",\n",
    "  \"moments_hu-5\",\n",
    "  \"moments_hu-6\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc8e3d5",
   "metadata": {},
   "source": [
    "Generate btrack objects and rescale 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e736651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/07/18 10:22:13 AM] Localizing objects from segmentation...\n",
      "[INFO][2022/07/18 10:22:21 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/07/18 10:22:21 AM] ...Found 7137 objects in 19 frames.\n"
     ]
    }
   ],
   "source": [
    "obj_from_arr = btrack.utils.segmentation_to_objects(stack, properties=tuple(FEATURES_Regionprops), scale=(1., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15cb7c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>area</th>\n",
       "      <th>major_axis_length</th>\n",
       "      <th>minor_axis_length</th>\n",
       "      <th>moments_hu-0</th>\n",
       "      <th>moments_hu-1</th>\n",
       "      <th>moments_hu-2</th>\n",
       "      <th>moments_hu-3</th>\n",
       "      <th>moments_hu-4</th>\n",
       "      <th>moments_hu-5</th>\n",
       "      <th>moments_hu-6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2076.339147</td>\n",
       "      <td>244.465088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>113759</td>\n",
       "      <td>731.861407</td>\n",
       "      <td>245.973569</td>\n",
       "      <td>0.327515</td>\n",
       "      <td>0.068138</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>6.384127e-07</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.346949e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 2076.3391467927813, 'y': 244.46508847651614, 'z': 0.0, 't': 0, 'dummy': False, 'states': 7, 'label': 5, 'area': 113759, 'major_axis_length': 731.8614068978937, 'minor_axis_length': 245.97356947194038, 'moments_hu-0': 0.32751480969930497, 'moments_hu-1': 0.06813836283722935, 'moments_hu-2': 0.0024447924965307114, 'moments_hu-3': 0.0005584168081887411, 'moments_hu-4': 6.384127279773245e-07, 'moments_hu-5': 0.00011780993485069929, 'moments_hu-6': 1.3469489798323727e-07}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first object\n",
    "obj_from_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f914b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>area</th>\n",
       "      <th>major_axis_length</th>\n",
       "      <th>minor_axis_length</th>\n",
       "      <th>moments_hu-0</th>\n",
       "      <th>moments_hu-1</th>\n",
       "      <th>moments_hu-2</th>\n",
       "      <th>moments_hu-3</th>\n",
       "      <th>moments_hu-4</th>\n",
       "      <th>moments_hu-5</th>\n",
       "      <th>moments_hu-6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2076.339147</td>\n",
       "      <td>244.465088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.757991</td>\n",
       "      <td>0.920582</td>\n",
       "      <td>0.674873</td>\n",
       "      <td>0.062656</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.026465</td>\n",
       "      <td>0.981495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 2076.3391467927813, 'y': 244.46508847651614, 'z': 0.0, 't': 0, 'dummy': False, 'states': 7, 'label': 5, 'area': 0.757990557846755, 'major_axis_length': 0.9205824356707641, 'minor_axis_length': 0.6748731946721799, 'moments_hu-0': 0.06265644868645973, 'moments_hu-1': 0.009748964001499954, 'moments_hu-2': 0.00032634649933089015, 'moments_hu-3': 8.07637834571293e-05, 'moments_hu-4': 0.0010280691034122548, 'moments_hu-5': 0.026464519027456196, 'moments_hu-6': 0.9814945816895987}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalise the visual features to range 0-1 # N.B. alters values for obj_from_arr also\n",
    "obj_from_arr_norm=normalise_visual_features(obj_from_arr)\n",
    "\n",
    "obj_from_arr_norm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc4e15",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Initialise a tracker session using a context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f3ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/06/13 03:34:27 PM] Loaded btrack: C:\\Users\\benevans\\Anaconda3\\envs\\Py37_btrack\\lib\\site-packages\\btrack\\libs\\libtracker.DLL\n",
      "[INFO][2022/06/13 03:34:27 PM] btrack (v0.5.0) library imported\n",
      "[INFO][2022/06/13 03:34:27 PM] Starting BayesianTracker session\n",
      "[INFO][2022/06/13 03:34:27 PM] Loading configuration file: data/ib_config.json\n",
      "[INFO][2022/06/13 03:34:27 PM] Objects are of type: <class 'list'>\n",
      "[INFO][2022/06/13 03:34:27 PM] Starting tracking... \n",
      "[INFO][2022/06/13 03:34:27 PM] Update using: ['MOTION', 'VISUAL']\n",
      "[INFO][2022/06/13 03:34:27 PM] Tracking objects in frames 0 to 19 (of 19)...\n",
      "[INFO][2022/06/13 03:34:27 PM]  - Timing (Bayesian updates: 0.00ms, Linking: 0.00ms)\n",
      "[INFO][2022/06/13 03:34:27 PM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/06/13 03:34:27 PM] SUCCESS.\n",
      "[INFO][2022/06/13 03:34:27 PM]  - Found 262 tracks in 19 frames (in 0.0s)\n",
      "[INFO][2022/06/13 03:34:27 PM]  - Inserted 255 dummy objects to fill tracking gaps\n",
      "[INFO][2022/06/13 03:34:27 PM] Opening HDF file: C:\\Users\\benevans\\OneDrive - NERC\\Documents\\Icebergs\\Tracking\\tracking_btrack\\data\\tracking.h5...\n",
      "[INFO][2022/06/13 03:34:27 PM] Writing tracks/obj_type_1\n",
      "[WARNING][2022/06/13 03:34:27 PM] Removing tracks/obj_type_1.\n",
      "[INFO][2022/06/13 03:34:27 PM] Writing dummies/obj_type_1\n",
      "[INFO][2022/06/13 03:34:27 PM] Writing LBEP/obj_type_1\n",
      "[INFO][2022/06/13 03:34:27 PM] Writing fates/obj_type_1\n",
      "[INFO][2022/06/13 03:34:27 PM] Closing HDF file: C:\\Users\\benevans\\OneDrive - NERC\\Documents\\Icebergs\\Tracking\\tracking_btrack\\data\\tracking.h5\n",
      "[INFO][2022/06/13 03:34:27 PM] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file('data/ib_config.json')\n",
    "    tracker.max_search_radius = 100\n",
    "\n",
    "    # set up the features to use as a list (before appending)\n",
    "    tracker.features = FEATURES\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(obj_from_arr_norm)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 3370), (0, 5315), (-1e5, 1e5))\n",
    "    #Z axis volume is set very large for 2D data)\n",
    "    \n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=50)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    #tracker.optimize()#docs suggest optimise motion model parameters first, then optimise hypothesis model\n",
    "\n",
    "    tracker.export(os.path.join(PATH, 'tracking.h5'), obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari(ndim=3)\n",
    "    \n",
    "    tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9e9d7",
   "metadata": {},
   "source": [
    "Visualise tracks with Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed83084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "napari.manifest -> 'btrack:napari.yaml' could not be imported: Could not find file 'napari.yaml' in module 'btrack'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Tracks layer 'Tracks' at 0x1e2909f0708>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(stack, scale=(1., 1., 1.), name='Segmentation')\n",
    "viewer.add_tracks(data, properties=properties, graph=graph, name='Tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c10cb8",
   "metadata": {},
   "source": [
    "Why does Napari generate many more segmentation timesteps than there are frames in the original stack of segmentations? \n",
    "\n",
    "Large objects appear not to have tracks assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6362ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Py37_btrack]",
   "language": "python",
   "name": "conda-env-Py37_btrack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
