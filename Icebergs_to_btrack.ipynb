{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe44a4c",
   "metadata": {},
   "source": [
    "# Import segmented iceberg maps to btrack and attempt tracking\n",
    "Perform Bayesian tracking of icebergs using 'btrack'. Much of the code here is copied from the btrack documentation\n",
    "https://github.com/quantumjot/BayesianTracker\n",
    "\n",
    "btrack v>=0.5 must be installed from branch 'visual-features'using Python 3.7. Conflicts arise with fiona when using Python 3.8\n",
    "\n",
    "Iceberg segmentations stored in 'data' folder are sample outputs of a fully unsupervised classifier for Sentinel-1 SAR imagery over a one-year period in 2019-2020.\n",
    "\n",
    "Initial testing uses a subset defined by the 'Thwaites_Tracking_subset' shapefile in the 'data' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2075f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import fiona\n",
    "import rasterio\n",
    "import btrack\n",
    "import napari\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.measure import regionprops, regionprops_table, label\n",
    "from skimage.morphology import remove_small_objects\n",
    "import DP_Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c44e5",
   "metadata": {},
   "source": [
    "Function to ensure all imported subsets are the same size as the first one processed even if underlying image extent and precise pixel geolocation differs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f9d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_clip(arr, rows,cols):\n",
    "    \n",
    "    if arr.shape[0]>rows:\n",
    "        arr=arr[0:rows, :]\n",
    "    elif arr.shape[0]<rows:\n",
    "        pad_rows=rows-arr.shape[0]\n",
    "        # npad is a tuple of (n_before, n_after) for each dimension\n",
    "        npad = ((0, pad_rows), (0, 0))\n",
    "        arr = np.pad(arr, pad_width=npad, mode='constant', constant_values=0)\n",
    "        \n",
    "    if arr.shape[1]>cols:\n",
    "        arr=arr[:, 0:cols]\n",
    "    elif arr.shape[1]<cols:\n",
    "        pad_cols=cols-arr.shape[1]\n",
    "        npad = ((0,0), (0, pad_cols))\n",
    "        arr = np.pad(arr, pad_width=npad, mode='constant', constant_values=0)\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb5d08",
   "metadata": {},
   "source": [
    "Function to construct a numpy array stack from segmentations in specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d62be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_arr(files, minsize=1):\n",
    "    \"\"\"Segmentation as numpy array.\"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    for filename in files:\n",
    "        imgWR=DP_Utils.load_to_WorkingRaster(filename, mask=shapes)\n",
    "        img=imgWR.data\n",
    "        \n",
    "        if filename == files[0]: #if first image get the shape to apply to subsequent images\n",
    "            rows=img.shape[0]\n",
    "            cols=img.shape[1]\n",
    "        \n",
    "        img=pad_or_clip(img, rows, cols)\n",
    "        labs=label(img, background=0)\n",
    "        cleaned= remove_small_objects(labs, min_size=minsize)\n",
    "        labs=label(cleaned, background=0)#re-label for continuous numbering\n",
    "        stack.append(labs)\n",
    "    return np.stack(stack, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd712c7",
   "metadata": {},
   "source": [
    "Function to rescale values of all visual features attached to btrack objects to interval 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f159fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise/rescale all attached features to range 0-1\n",
    "def normalise_visual_features(objects):\n",
    "    import copy\n",
    "    objects2=copy.copy(objects)#TODO doesn't seem to stop original objects changing\n",
    "    #initialise variables to store min and max of each\n",
    "    min_vals={}\n",
    "    max_vals={}\n",
    "    #Loop objects to find min and max for each property\n",
    "    for obj in objects2:\n",
    "        for prop in obj.properties:\n",
    "            #collate minimum values\n",
    "            if prop in min_vals:\n",
    "                if min_vals[prop]>obj.properties[prop]:#if smaller than current min\n",
    "                    min_vals[prop]=obj.properties[prop]\n",
    "            else:\n",
    "                min_vals[prop]=obj.properties[prop]#add dictionary entry with value\n",
    "        \n",
    "            #repeat for maximum values\n",
    "            if prop in max_vals:\n",
    "                if max_vals[prop]<obj.properties[prop]:\n",
    "                    max_vals[prop]=obj.properties[prop] # if bigger than current max\n",
    "            else:\n",
    "                max_vals[prop]=obj.properties[prop]\n",
    "    \n",
    "    #Repeat the loop over objects and min-max scale the property values\n",
    "    for obj in objects2:\n",
    "        for prop in obj.properties:\n",
    "            newprop=(obj.properties[prop]-min_vals[prop])/(max_vals[prop]-min_vals[prop])\n",
    "            obj.properties[prop]=newprop\n",
    "            \n",
    "    return objects2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29e19d",
   "metadata": {},
   "source": [
    "Set up paths to example data and ROI shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b56e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=os.path.join(Path().resolve(), \"data\")\n",
    "#PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551f002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to subsetting polygon shapefile\n",
    "SubsetPolygon = os.path.join(PATH , 'Shapefile\\Thwaites_Tracking_subset.shp')\n",
    "#SubsetPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f7c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example segmentations\n",
    "files = glob.glob(os.path.join(PATH, 'Iceberg_Detections\\Icebergs*.tif'))\n",
    "#files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c318e",
   "metadata": {},
   "source": [
    "Open subset polygon for clipping of output rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f18c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fiona.open(SubsetPolygon, \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "#shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a04562",
   "metadata": {},
   "source": [
    "Build stack of segmented images including only objects greater than specified size (lower limit for detection algorithm is 63 pixels or 0.1km^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7831748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 5315, 3370)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack = segmentation_arr(files, minsize=2000)\n",
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a5494",
   "metadata": {},
   "source": [
    "Define visual features to calculate in call to regionprops and then those that we want to use in tracking updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4863d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to be computed by regionprops\n",
    "FEATURES_Regionprops = [\n",
    "  \"area\",\n",
    "  \"major_axis_length\",\n",
    "  \"minor_axis_length\",\n",
    "  \"moments_hu\"\n",
    "]\n",
    "\n",
    "# features to be used for tracking updates - note that each Hu moment we want to use needs to be specified individually - \n",
    "# hence can't just pass Features_Regionprops\n",
    "FEATURES = [\n",
    "  \"area\",\n",
    "  \"major_axis_length\",\n",
    "  \"minor_axis_length\",\n",
    "  \"moments_hu-0\",\n",
    "  \"moments_hu-1\",\n",
    "  \"moments_hu-2\",\n",
    "  \"moments_hu-3\",\n",
    "  \"moments_hu-4\",\n",
    "  \"moments_hu-5\",\n",
    "  \"moments_hu-6\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc8e3d5",
   "metadata": {},
   "source": [
    "Generate btrack objects and rescale 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e736651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/06/13 03:32:02 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/06/13 03:32:08 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/06/13 03:32:08 PM] ...Found 679 objects in 19 frames.\n"
     ]
    }
   ],
   "source": [
    "obj_from_arr = btrack.utils.segmentation_to_objects(stack, properties=tuple(FEATURES_Regionprops), scale=(1., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15cb7c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>area</th>\n",
       "      <th>major_axis_length</th>\n",
       "      <th>minor_axis_length</th>\n",
       "      <th>moments_hu-0</th>\n",
       "      <th>moments_hu-1</th>\n",
       "      <th>moments_hu-2</th>\n",
       "      <th>moments_hu-3</th>\n",
       "      <th>moments_hu-4</th>\n",
       "      <th>moments_hu-5</th>\n",
       "      <th>moments_hu-6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2076.339147</td>\n",
       "      <td>244.465088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>113759</td>\n",
       "      <td>731.861407</td>\n",
       "      <td>245.973569</td>\n",
       "      <td>0.327515</td>\n",
       "      <td>0.068138</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>6.384127e-07</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.346949e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 2076.3391467927813, 'y': 244.46508847651614, 'z': 0.0, 't': 0, 'dummy': False, 'states': 7, 'label': 5, 'area': 113759, 'major_axis_length': 731.8614068978937, 'minor_axis_length': 245.97356947194038, 'moments_hu-0': 0.32751480969930497, 'moments_hu-1': 0.06813836283722935, 'moments_hu-2': 0.0024447924965307114, 'moments_hu-3': 0.0005584168081887411, 'moments_hu-4': 6.384127279773245e-07, 'moments_hu-5': 0.00011780993485069929, 'moments_hu-6': 1.3469489798323727e-07}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first object\n",
    "obj_from_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f914b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>area</th>\n",
       "      <th>major_axis_length</th>\n",
       "      <th>minor_axis_length</th>\n",
       "      <th>moments_hu-0</th>\n",
       "      <th>moments_hu-1</th>\n",
       "      <th>moments_hu-2</th>\n",
       "      <th>moments_hu-3</th>\n",
       "      <th>moments_hu-4</th>\n",
       "      <th>moments_hu-5</th>\n",
       "      <th>moments_hu-6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2076.339147</td>\n",
       "      <td>244.465088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.757991</td>\n",
       "      <td>0.920582</td>\n",
       "      <td>0.674873</td>\n",
       "      <td>0.062656</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.026465</td>\n",
       "      <td>0.981495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 2076.3391467927813, 'y': 244.46508847651614, 'z': 0.0, 't': 0, 'dummy': False, 'states': 7, 'label': 5, 'area': 0.757990557846755, 'major_axis_length': 0.9205824356707641, 'minor_axis_length': 0.6748731946721799, 'moments_hu-0': 0.06265644868645973, 'moments_hu-1': 0.009748964001499954, 'moments_hu-2': 0.00032634649933089015, 'moments_hu-3': 8.07637834571293e-05, 'moments_hu-4': 0.0010280691034122548, 'moments_hu-5': 0.026464519027456196, 'moments_hu-6': 0.9814945816895987}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalise the visual features to range 0-1 # N.B. alters values for obj_from_arr also\n",
    "obj_from_arr_norm=normalise_visual_features(obj_from_arr)\n",
    "\n",
    "obj_from_arr_norm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc4e15",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Initialise a tracker session using a context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f3ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/06/13 03:34:27 PM] Loaded btrack: C:\\Users\\benevans\\Anaconda3\\envs\\Py37_btrack\\lib\\site-packages\\btrack\\libs\\libtracker.DLL\n",
      "[INFO][2022/06/13 03:34:27 PM] btrack (v0.5.0) library imported\n",
      "[INFO][2022/06/13 03:34:27 PM] Starting BayesianTracker session\n",
      "[INFO][2022/06/13 03:34:27 PM] Loading configuration file: data/ib_config.json\n",
      "[INFO][2022/06/13 03:34:27 PM] Objects are of type: <class 'list'>\n",
      "[INFO][2022/06/13 03:34:27 PM] Starting tracking... \n",
      "[INFO][2022/06/13 03:34:27 PM] Update using: ['MOTION', 'VISUAL']\n",
      "[INFO][2022/06/13 03:34:27 PM] Tracking objects in frames 0 to 19 (of 19)...\n",
      "[INFO][2022/06/13 03:34:27 PM]  - Timing (Bayesian updates: 0.00ms, Linking: 0.00ms)\n",
      "[INFO][2022/06/13 03:34:27 PM]  - Probabilities (Link: 0.99999, Lost: 1.00000)\n",
      "[INFO][2022/06/13 03:34:27 PM] SUCCESS.\n",
      "[INFO][2022/06/13 03:34:27 PM]  - Found 262 tracks in 19 frames (in 0.0s)\n",
      "[INFO][2022/06/13 03:34:27 PM]  - Inserted 255 dummy objects to fill tracking gaps\n",
      "[INFO][2022/06/13 03:34:27 PM] Opening HDF file: C:\\Users\\benevans\\OneDrive - NERC\\Documents\\Icebergs\\Tracking\\tracking_btrack\\data\\tracking.h5...\n",
      "[INFO][2022/06/13 03:34:27 PM] Writing tracks/obj_type_1\n",
      "[WARNING][2022/06/13 03:34:27 PM] Removing tracks/obj_type_1.\n",
      "[INFO][2022/06/13 03:34:27 PM] Writing dummies/obj_type_1\n",
      "[INFO][2022/06/13 03:34:27 PM] Writing LBEP/obj_type_1\n",
      "[INFO][2022/06/13 03:34:27 PM] Writing fates/obj_type_1\n",
      "[INFO][2022/06/13 03:34:27 PM] Closing HDF file: C:\\Users\\benevans\\OneDrive - NERC\\Documents\\Icebergs\\Tracking\\tracking_btrack\\data\\tracking.h5\n",
      "[INFO][2022/06/13 03:34:27 PM] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file('data/ib_config.json')\n",
    "    tracker.max_search_radius = 100\n",
    "\n",
    "    # set up the features to use as a list (before appending)\n",
    "    tracker.features = FEATURES\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(obj_from_arr_norm)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 3370), (0, 5315), (-1e5, 1e5))\n",
    "    #Z axis volume is set very large for 2D data)\n",
    "    \n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=50)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    #tracker.optimize()#docs suggest optimise motion model parameters first, then optimise hypothesis model\n",
    "\n",
    "    tracker.export(os.path.join(PATH, 'tracking.h5'), obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari(ndim=3)\n",
    "    \n",
    "    tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9e9d7",
   "metadata": {},
   "source": [
    "Visualise tracks with Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed83084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "napari.manifest -> 'btrack:napari.yaml' could not be imported: Could not find file 'napari.yaml' in module 'btrack'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Tracks layer 'Tracks' at 0x1e2909f0708>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(stack, scale=(1., 1., 1.), name='Segmentation')\n",
    "viewer.add_tracks(data, properties=properties, graph=graph, name='Tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c10cb8",
   "metadata": {},
   "source": [
    "Why does Napari generate many more segmentation timesteps than there are frames in the original stack of segmentations? \n",
    "\n",
    "Large objects appear not to have tracks assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6362ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Py37_btrack] *",
   "language": "python",
   "name": "conda-env-Py37_btrack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
